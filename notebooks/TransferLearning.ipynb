{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TransferLearning.ipynb","provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyOwl2eBIkOj7ODSrT+PyUwG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"032cbe4f0ed74075ab5d1a5a199b6a9f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cf3d5c8a9d6d449fa717b254cf5bf0e3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_402bf0daf4424e5e9af51065c634b69f","IPY_MODEL_38603b853f0242cca81d4ff17b1a78c5"]}},"cf3d5c8a9d6d449fa717b254cf5bf0e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"402bf0daf4424e5e9af51065c634b69f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6c22a43f46d94fe6ac0058a09e892dc0","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":17542753,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":17542753,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7f4009c961b14e7aacd9a1d3d83460f5"}},"38603b853f0242cca81d4ff17b1a78c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3853d48751304b7b8294b4a5ba6d690c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 16.7M/16.7M [00:10&lt;00:00, 1.75MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fd201c22a4b34c1987837731a4c51b3a"}},"6c22a43f46d94fe6ac0058a09e892dc0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7f4009c961b14e7aacd9a1d3d83460f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3853d48751304b7b8294b4a5ba6d690c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fd201c22a4b34c1987837731a4c51b3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I5lqe3G4uST0","executionInfo":{"status":"ok","timestamp":1620461367431,"user_tz":-180,"elapsed":21917,"user":{"displayName":"Anton Maksimov","photoUrl":"","userId":"13041519752486250158"}},"outputId":"e074fb03-1cd0-4dca-99dd-aae7395858ab"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ewCb47T9uYty","executionInfo":{"status":"ok","timestamp":1620461367432,"user_tz":-180,"elapsed":6252,"user":{"displayName":"Anton Maksimov","photoUrl":"","userId":"13041519752486250158"}},"outputId":"aa5154ca-44cf-413a-def8-bc723c7617d9"},"source":["cd /content/gdrive/'My Drive'/Diploma"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/Diploma\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xwfHZkAYLsGU","executionInfo":{"status":"ok","timestamp":1620461378213,"user_tz":-180,"elapsed":15858,"user":{"displayName":"Anton Maksimov","photoUrl":"","userId":"13041519752486250158"}},"outputId":"3be1aa93-5bfc-4295-f2a0-68cee9e85739"},"source":["!pip install segmentation-models-pytorch\n","from zipfile import ZipFile\n","import useful\n","import numpy as np\n","import torch\n","import segmentation_models_pytorch as smp\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import math\n","from torch.utils.data import Dataset, DataLoader\n","from data import DepthDataset, RandomHorizontalFlip, ToTensorTest, ToTensorTrain, RandomRotate\n","from torchvision import transforms\n","from PIL import ImageFilter\n","import matplotlib.pyplot as plt\n","from io import BytesIO\n","from PIL import Image"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting segmentation-models-pytorch\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/54/8953f9f7ee9d451b0f3be8d635aa3a654579abf898d17502a090efe1155a/segmentation_models_pytorch-0.1.3-py3-none-any.whl (66kB)\n","\u001b[K     |████████████████████████████████| 71kB 5.4MB/s \n","\u001b[?25hCollecting timm==0.3.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/2d/39ecc56fbb202e1891c317e8e44667299bc3b0762ea2ed6aaaa2c2f6613c/timm-0.3.2-py3-none-any.whl (244kB)\n","\u001b[K     |████████████████████████████████| 245kB 15.4MB/s \n","\u001b[?25hCollecting pretrainedmodels==0.7.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/0e/be6a0e58447ac16c938799d49bfb5fb7a80ac35e137547fc6cee2c08c4cf/pretrainedmodels-0.7.4.tar.gz (58kB)\n","\u001b[K     |████████████████████████████████| 61kB 10.3MB/s \n","\u001b[?25hCollecting efficientnet-pytorch==0.6.3\n","  Downloading https://files.pythonhosted.org/packages/b8/cb/0309a6e3d404862ae4bc017f89645cf150ac94c14c88ef81d215c8e52925/efficientnet_pytorch-0.6.3.tar.gz\n","Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from segmentation-models-pytorch) (0.9.1+cu101)\n","Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.7/dist-packages (from timm==0.3.2->segmentation-models-pytorch) (1.8.1+cu101)\n","Collecting munch\n","  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (4.41.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.3.0->segmentation-models-pytorch) (1.19.5)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.3.0->segmentation-models-pytorch) (7.1.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->timm==0.3.2->segmentation-models-pytorch) (3.7.4.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from munch->pretrainedmodels==0.7.4->segmentation-models-pytorch) (1.15.0)\n","Building wheels for collected packages: pretrainedmodels, efficientnet-pytorch\n","  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-cp37-none-any.whl size=60963 sha256=96547be4534c07c1116bea58cc74393cbe0e7f7edabfa8350f42ab7bfe6002c8\n","  Stored in directory: /root/.cache/pip/wheels/69/df/63/62583c096289713f22db605aa2334de5b591d59861a02c2ecd\n","  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-cp37-none-any.whl size=12420 sha256=f1301de428746c4aa3657a77c899749537ea6992f112baa7897e1907a9e1e075\n","  Stored in directory: /root/.cache/pip/wheels/42/1e/a9/2a578ba9ad04e776e80bf0f70d8a7f4c29ec0718b92d8f6ccd\n","Successfully built pretrainedmodels efficientnet-pytorch\n","Installing collected packages: timm, munch, pretrainedmodels, efficientnet-pytorch, segmentation-models-pytorch\n","Successfully installed efficientnet-pytorch-0.6.3 munch-2.5.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.1.3 timm-0.3.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"luTJwLUkBhFX","executionInfo":{"status":"ok","timestamp":1620461379694,"user_tz":-180,"elapsed":1472,"user":{"displayName":"Anton Maksimov","photoUrl":"","userId":"13041519752486250158"}}},"source":["def berHuLoss(pred, target):\n","    huber_c = torch.max(pred - target)\n","    huber_c = 0.2 * huber_c\n","    valid_mask = (target > 0).detach()\n","    diff = target - pred\n","    diff = diff[valid_mask]\n","    diff = diff.abs()\n","    huber_mask = (diff > huber_c).detach()\n","    diff2 = diff[huber_mask]\n","    diff2 = diff2 ** 2\n","    loss = torch.cat((diff, diff2)).mean()\n","    return loss\n","\n","def edges_loss(pred, target, alpha=1):\n","    def gradient(x):\n","        h_x = x.size()[-2]\n","        w_x = x.size()[-1]\n","        left = x\n","        right = F.pad(x, [0, 1, 0, 0])[:, :, :, 1:]\n","        top = x\n","        bottom = F.pad(x, [0, 0, 0, 1])[:, :, 1:, :]\n","        dx, dy = right - left, bottom - top \n","        dx[:, :, :, -1] = 0\n","        dy[:, :, -1, :] = 0\n","        return dx, dy\n","    gen_dx, gen_dy = gradient(pred)\n","    gt_dx, gt_dy = gradient(target)\n","    grad_diff_x = torch.abs(gt_dx - gen_dx)\n","    grad_diff_y = torch.abs(gt_dy - gen_dy)\n","\n","    return torch.mean(grad_diff_x ** alpha + grad_diff_y ** alpha)\n","\n","\n","def gaussian(window_size, sigma):\n","    gauss = torch.Tensor([math.exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n","    return gauss/gauss.sum()\n","\n","def create_window(window_size, channel=1):\n","    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n","    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n","    window = _2D_window.expand(channel, 1, window_size, window_size).contiguous()\n","    return window\n","\n","def ssim(img1, img2, val_range, window_size=11, window=None, size_average=True, full=False):\n","    L = val_range\n","\n","    padd = 0\n","    (_, channel, height, width) = img1.size()\n","    if window is None:\n","        real_size = min(window_size, height, width)\n","        window = create_window(real_size, channel=channel).to(img1.device)\n","\n","    mu1 = F.conv2d(img1, window, padding=padd, groups=channel)\n","    mu2 = F.conv2d(img2, window, padding=padd, groups=channel)\n","\n","    mu1_sq = mu1.pow(2)\n","    mu2_sq = mu2.pow(2)\n","    mu1_mu2 = mu1 * mu2\n","\n","    sigma1_sq = F.conv2d(img1 * img1, window, padding=padd, groups=channel) - mu1_sq\n","    sigma2_sq = F.conv2d(img2 * img2, window, padding=padd, groups=channel) - mu2_sq\n","    sigma12 = F.conv2d(img1 * img2, window, padding=padd, groups=channel) - mu1_mu2\n","\n","    C1 = (0.01 * L) ** 2\n","    C2 = (0.03 * L) ** 2\n","\n","    v1 = 2.0 * sigma12 + C2\n","    v2 = sigma1_sq + sigma2_sq + C2\n","    cs = torch.mean(v1 / v2)  # contrast sensitivity\n","\n","    ssim_map = ((2 * mu1_mu2 + C1) * v1) / ((mu1_sq + mu2_sq + C1) * v2)\n","\n","    if size_average:\n","        ret = ssim_map.mean()\n","    else:\n","        ret = ssim_map.mean(1).mean(1).mean(1)\n","\n","    if full:\n","        return ret, cs\n","\n","    return ret"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"_lJdEalUyyWG","executionInfo":{"status":"ok","timestamp":1620461379695,"user_tz":-180,"elapsed":1463,"user":{"displayName":"Anton Maksimov","photoUrl":"","userId":"13041519752486250158"}}},"source":["class RandomChannelSwap(object):\n","    def __init__(self, probability):\n","        from itertools import permutations\n","        self.probability = probability\n","        self.indices = list(permutations(range(3), 3))\n","\n","    def __call__(self, sample):\n","        image, depth = sample['image'], sample['depth']\n","        if not _is_pil_image(image): raise TypeError('img should be PIL Image. Got {}'.format(type(image)))\n","        if not _is_pil_image(depth): raise TypeError('img should be PIL Image. Got {}'.format(type(depth)))\n","        if random.random() < self.probability:\n","            image = np.asarray(image)\n","            image = Image.fromarray(image[...,list(self.indices[random.randint(0, len(self.indices) - 1)])])\n","        return {'image': image, 'depth': depth}"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"sqL23QyWzfZL","executionInfo":{"status":"ok","timestamp":1620461379696,"user_tz":-180,"elapsed":1455,"user":{"displayName":"Anton Maksimov","photoUrl":"","userId":"13041519752486250158"}}},"source":["class ColorJitter(object):\n","    def __init__(self, brightness=0, contrast=0, saturation=0, hue=0):\n","        self.brightness = brightness\n","        self.contrast = contrast\n","        self.saturation = saturation\n","        self.hue = hue\n","        self.color_jitter = transforms.ColorJitter(brightness=self.brightness, contrast=self.contrast, saturation=self.saturation, hue=self.hue)\n","    def __call__(self, sample):\n","        image, depth = sample['image'], sample['depth']\n","\n","        return {'image': self.color_jitter(image), 'depth': depth}\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"asldBAun54h0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qWt9t_Hl2AD1","executionInfo":{"status":"ok","timestamp":1620461439444,"user_tz":-180,"elapsed":61193,"user":{"displayName":"Anton Maksimov","photoUrl":"","userId":"13041519752486250158"}},"outputId":"c724d636-3457-48e8-bab3-d03f517b6ee9"},"source":["data, nyu2_train, nyu2_test  = useful.load_zip('nyu_data.zip')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Loading dataset zip file...Loaded (50688).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LSlpuijqT32h","executionInfo":{"status":"ok","timestamp":1620461439445,"user_tz":-180,"elapsed":61186,"user":{"displayName":"Anton Maksimov","photoUrl":"","userId":"13041519752486250158"}}},"source":["PATH_models = f'/content/gdrive/MyDrive/Diploma/Models/'\n","PATH_metrics = f'/content/gdrive/MyDrive/Diploma/Metrics/'"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"ThjIdn-QxMgs","executionInfo":{"status":"ok","timestamp":1620461439446,"user_tz":-180,"elapsed":61178,"user":{"displayName":"Anton Maksimov","photoUrl":"","userId":"13041519752486250158"}}},"source":["def load_checkpoint(model, load_path):\n","    state_dict = torch.load(PATH_models + load_path)\n","    model.load_state_dict(state_dict['model_state_dict'])\n","    return model"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"pKMKR0a7NrP8","colab":{"base_uri":"https://localhost:8080/","height":105,"referenced_widgets":["032cbe4f0ed74075ab5d1a5a199b6a9f","cf3d5c8a9d6d449fa717b254cf5bf0e3","402bf0daf4424e5e9af51065c634b69f","38603b853f0242cca81d4ff17b1a78c5","6c22a43f46d94fe6ac0058a09e892dc0","7f4009c961b14e7aacd9a1d3d83460f5","3853d48751304b7b8294b4a5ba6d690c","fd201c22a4b34c1987837731a4c51b3a"]},"executionInfo":{"status":"ok","timestamp":1620461454890,"user_tz":-180,"elapsed":15424,"user":{"displayName":"Anton Maksimov","photoUrl":"","userId":"13041519752486250158"}},"outputId":"819af6a8-55dc-4f54-8276-8e56db5117ce"},"source":["model_seg = smp.Unet(encoder_name=\"timm-regnety_004\", \n","                encoder_weights=\"imagenet\",\n","                in_channels=3,                  \n","                classes=40\n","                )\n","model_seg.cuda()\n","model_seg = load_checkpoint(model_seg, 'seg_model_130ep.pt')\n","\n","\n","model_dep = smp.Unet(encoder_name=\"timm-regnety_004\", \n","                encoder_weights=\"imagenet\",\n","                in_channels=3,                  \n","                classes=1\n","                )\n","model_dep.cuda()\n","model_dep = load_checkpoint(model_dep, 'base_timm-regnety_004_model.pth')"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnety_004-0db870e6.pth\" to /root/.cache/torch/hub/checkpoints/regnety_004-0db870e6.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"032cbe4f0ed74075ab5d1a5a199b6a9f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=17542753.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vqy_rL81TusF","executionInfo":{"status":"ok","timestamp":1620461454891,"user_tz":-180,"elapsed":15413,"user":{"displayName":"Anton Maksimov","photoUrl":"","userId":"13041519752486250158"}}},"source":["model_dep.decoder.blocks[4] = model_seg.decoder.blocks[4]"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"O7Y5IP34URdr","executionInfo":{"status":"ok","timestamp":1620461454892,"user_tz":-180,"elapsed":15404,"user":{"displayName":"Anton Maksimov","photoUrl":"","userId":"13041519752486250158"}}},"source":["for param in model_dep.parameters():\n","  param.requires_grad = True"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"7SRjdzRlxdfX","executionInfo":{"status":"ok","timestamp":1620461454893,"user_tz":-180,"elapsed":15396,"user":{"displayName":"Anton Maksimov","photoUrl":"","userId":"13041519752486250158"}}},"source":["for param in model_dep.decoder.blocks[4].parameters():\n","  param.requires_grad = False"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"ICWjW9oMBuid","executionInfo":{"status":"ok","timestamp":1620462250519,"user_tz":-180,"elapsed":920,"user":{"displayName":"Anton Maksimov","photoUrl":"","userId":"13041519752486250158"}}},"source":["model_dep = load_checkpoint(model_dep, 'transfer_model.pt')"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"QahTgwsRS5MI","executionInfo":{"status":"ok","timestamp":1620461488248,"user_tz":-180,"elapsed":916,"user":{"displayName":"Anton Maksimov","photoUrl":"","userId":"13041519752486250158"}}},"source":["batch_size = 16"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"dQFjPf2WTzDo","executionInfo":{"status":"ok","timestamp":1620461488720,"user_tz":-180,"elapsed":541,"user":{"displayName":"Anton Maksimov","photoUrl":"","userId":"13041519752486250158"}}},"source":["transformed_dataset_train = DepthDataset(data, nyu2_train,transform=transforms.Compose([\n","                                                                                        \n","                                               ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.4),\n","                                               RandomHorizontalFlip(),\n","                                               RandomRotate(5),\n","                                               ToTensorTrain()\n","                                                           ]))\n","train_loader = DataLoader(transformed_dataset_train, batch_size, shuffle=True)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"saRfZD28ebLg","executionInfo":{"status":"ok","timestamp":1620461489612,"user_tz":-180,"elapsed":428,"user":{"displayName":"Anton Maksimov","photoUrl":"","userId":"13041519752486250158"}}},"source":["transformed_dataset_test = DepthDataset(data, nyu2_test, transform=transforms.Compose([\n","                                               ToTensorTest()\n","                                                           ]))\n","test_loader = DataLoader(transformed_dataset_test, batch_size, shuffle=True)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"NW_nTJmgZVwU","executionInfo":{"status":"ok","timestamp":1620462261052,"user_tz":-180,"elapsed":761,"user":{"displayName":"Anton Maksimov","photoUrl":"","userId":"13041519752486250158"}}},"source":["def trainer(model, learning_rate = 0.0001, epochs = 10, eval_every = 1, best_test_loss = float(\"Inf\"),\n","            save_path_metrics = 'transfer_metrics2.pt',\n","            save_path_model = 'transfer_model2.pt', optimizer=None):\n","  l1_criterion = nn.L1Loss()\n","  if optimizer is None:\n","    optimizer = torch.optim.Adam( model.parameters(), learning_rate)\n","  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=19008, gamma=0.1)\n","  global_step = 0\n","  running_loss = 0.0             \n","  test_running_loss = 0.0\n","\n","  model.train()\n","\n","  train_losses_list = []\n","  test_losses_list = []\n","  global_steps_list = []\n","\n","  for epoch in range(epochs):\n","\n","      for i, sample_batched in enumerate(train_loader):\n","          global_step += 1\n","          optimizer.zero_grad()\n","          image = torch.autograd.Variable(sample_batched['image'].cuda())\n","          depth = torch.autograd.Variable(sample_batched['depth'].cuda(non_blocking=True))\n","          depth_n = useful.normalize_depth(depth)\n","          output = model(image)\n","\n","          loss_l1 = l1_criterion(output, depth_n)\n","          loss_ssim = torch.clamp((1 - ssim(output, depth_n, val_range = 1000.0 / 10.0)) * 0.5, 0, 1)\n","          loss_edges = edges_loss(output, depth_n)\n","          loss_depth = loss_ssim + loss_edges + loss_l1*0.1\n","          loss_depth.backward()\n","          optimizer.step()\n","          scheduler.step()\n","          running_loss += loss_depth.item()\n","\n","      if global_step % eval_every == 0:\n","\n","          model.eval()\n","\n","          with torch.no_grad():\n","              for i, sample_batched in enumerate(test_loader):\n","\n","                  image = torch.autograd.Variable(sample_batched['image'].cuda())\n","                  depth = torch.autograd.Variable(sample_batched['depth'].cuda(non_blocking=True))\n","                  depth_n = useful.normalize_depth(depth)\n","                  output = model(image)\n","                  loss_l1 = l1_criterion(output, depth_n)\n","                  loss_ssim = torch.clamp((1 - ssim(output, depth_n, val_range = 1000.0 / 10.0)) * 0.5, 0, 1)\n","                  loss_edges = edges_loss(output, depth_n)\n","                  loss_depth = loss_ssim + loss_edges + loss_l1*0.1\n","                  test_running_loss += loss_depth.item()\n","                  #TODO\n","\n","                           \n","          average_train_loss = running_loss / len(train_loader)\n","          average_test_loss = test_running_loss / len(test_loader)    \n","          train_losses_list.append(average_train_loss)\n","          test_losses_list.append(average_test_loss)\n","          global_steps_list.append(global_step)\n","\n","          running_loss = 0.0                \n","          test_running_loss = 0.0\n","\n","          model.train()\n","\n","          print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.5f}, Test Loss: {:.5f}'\n","                      .format(epoch+1, epochs, global_step, epochs*len(train_loader),\n","                              average_train_loss, average_test_loss))\n","          \n","          if (best_test_loss > average_test_loss): #and (average_train_loss < average_test_loss):\n","\n","              best_test_loss = average_test_loss\n","              #Metrics saving\n","              state_dict = {'train_losses_list': train_losses_list,\n","                            'test_losses_list': test_losses_list,\n","                            'global_steps_list': global_steps_list\n","                           }\n","\n","              torch.save(state_dict, PATH_metrics + save_path_metrics)\n","              print(f'Metrics saved to ==> {save_path_metrics}')\n","              #Model saving\n","              state_dict = {\n","                            'model_state_dict': model.state_dict(),\n","                            'best_test_loss': best_test_loss,\n","                            'optimizer_state_dict': optimizer.state_dict(),\n","                            'epoch': epoch\n","                           }\n","              torch.save(state_dict, PATH_models+save_path_model)\n","              print(f'Model saved to ==> {save_path_model}')\n","\n","  print(\"Training finished.\")"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D2XooQDLVrY4","outputId":"86d66d4d-f4e6-4ccd-d615-7d0a6e037abb"},"source":["trainer(model_dep, learning_rate = 0.0001, epochs = 8)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch [1/8], Step [3168/25344], Train Loss: 0.60783, Test Loss: 0.12910\n","Metrics saved to ==> transfer_metrics.pt\n","Model saved to ==> transfer_model.pt\n","Epoch [2/8], Step [6336/25344], Train Loss: 0.36228, Test Loss: 0.12624\n","Metrics saved to ==> transfer_metrics.pt\n","Model saved to ==> transfer_model.pt\n","Epoch [3/8], Step [9504/25344], Train Loss: 0.26337, Test Loss: 0.12304\n","Metrics saved to ==> transfer_metrics.pt\n","Model saved to ==> transfer_model.pt\n","Epoch [4/8], Step [12672/25344], Train Loss: 0.22471, Test Loss: 0.11948\n","Metrics saved to ==> transfer_metrics.pt\n","Model saved to ==> transfer_model.pt\n","Epoch [5/8], Step [15840/25344], Train Loss: 0.21127, Test Loss: 0.11827\n","Metrics saved to ==> transfer_metrics.pt\n","Model saved to ==> transfer_model.pt\n","Epoch [6/8], Step [19008/25344], Train Loss: 0.20286, Test Loss: 0.11926\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ixznr3IEsG6","outputId":"440ce5bb-a784-46e4-a85b-f12a300fe96c"},"source":["trainer(model_dep, learning_rate = 0.001, epochs = 8)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch [1/8], Step [3168/25344], Train Loss: 0.20719, Test Loss: 0.12123\n","Metrics saved to ==> transfer_metrics2.pt\n","Model saved to ==> transfer_model2.pt\n","Epoch [2/8], Step [6336/25344], Train Loss: 0.18058, Test Loss: 0.12214\n"],"name":"stdout"}]}]}